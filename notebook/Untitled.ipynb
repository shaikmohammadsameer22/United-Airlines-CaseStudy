{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45275258-5da5-4613-919f-1c32a66d0b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: ['Airports Data.csv', 'Bag+Level+Data.csv', 'Flight Level Data.csv', 'PNR Remark Level Data.csv', 'PNR+Flight+Level+Data.csv']\n",
      "\n",
      "Checking nulls for: Airports Data.csv\n",
      "airport_iata_code     0\n",
      "iso_country_code     15\n",
      "dtype: int64\n",
      "airport_iata_code    0.000000\n",
      "iso_country_code     0.267284\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: Bag+Level+Data.csv\n",
      "company_id                          0\n",
      "flight_number                       0\n",
      "scheduled_departure_date_local      0\n",
      "scheduled_departure_station_code    0\n",
      "scheduled_arrival_station_code      0\n",
      "bag_tag_unique_number               0\n",
      "bag_tag_issue_date                  0\n",
      "bag_type                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 2: Define the folder path where your CSV files are\n",
    "folder_path = r\"C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\"\n",
    "\n",
    "# Step 3: List all CSV files in that folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "print(\"CSV files found:\", csv_files)\n",
    "\n",
    "# Step 4: Loop through each CSV file and check for null values\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"\\nChecking nulls for: {file}\")\n",
    "    print(df.isnull().sum())  # shows null counts per column\n",
    "    print(df.isnull().mean() * 100)  # shows % of nulls per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd87d9cb-1ed0-49df-a01b-e4d96db7f083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: ['Airports Data.csv', 'Bag+Level+Data.csv', 'Flight Level Data.csv', 'PNR Remark Level Data.csv', 'PNR+Flight+Level+Data.csv']\n",
      "\n",
      "Checking nulls for: Airports Data.csv\n",
      "airport_iata_code     0\n",
      "iso_country_code     15\n",
      "dtype: int64\n",
      "airport_iata_code    0.000000\n",
      "iso_country_code     0.267284\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: Bag+Level+Data.csv\n",
      "company_id                          0\n",
      "flight_number                       0\n",
      "scheduled_departure_date_local      0\n",
      "scheduled_departure_station_code    0\n",
      "scheduled_arrival_station_code      0\n",
      "bag_tag_unique_number               0\n",
      "bag_tag_issue_date                  0\n",
      "bag_type                            0\n",
      "dtype: int64\n",
      "company_id                          0.0\n",
      "flight_number                       0.0\n",
      "scheduled_departure_date_local      0.0\n",
      "scheduled_departure_station_code    0.0\n",
      "scheduled_arrival_station_code      0.0\n",
      "bag_tag_unique_number               0.0\n",
      "bag_tag_issue_date                  0.0\n",
      "bag_type                            0.0\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: Flight Level Data.csv\n",
      "company_id                            0\n",
      "flight_number                         0\n",
      "scheduled_departure_date_local        0\n",
      "scheduled_departure_station_code      0\n",
      "scheduled_arrival_station_code        0\n",
      "scheduled_departure_datetime_local    0\n",
      "scheduled_arrival_datetime_local      0\n",
      "actual_departure_datetime_local       0\n",
      "actual_arrival_datetime_local         0\n",
      "total_seats                           0\n",
      "fleet_type                            0\n",
      "carrier                               0\n",
      "scheduled_ground_time_minutes         0\n",
      "actual_ground_time_minutes            0\n",
      "minimum_turn_minutes                  0\n",
      "dtype: int64\n",
      "company_id                            0.0\n",
      "flight_number                         0.0\n",
      "scheduled_departure_date_local        0.0\n",
      "scheduled_departure_station_code      0.0\n",
      "scheduled_arrival_station_code        0.0\n",
      "scheduled_departure_datetime_local    0.0\n",
      "scheduled_arrival_datetime_local      0.0\n",
      "actual_departure_datetime_local       0.0\n",
      "actual_arrival_datetime_local         0.0\n",
      "total_seats                           0.0\n",
      "fleet_type                            0.0\n",
      "carrier                               0.0\n",
      "scheduled_ground_time_minutes         0.0\n",
      "actual_ground_time_minutes            0.0\n",
      "minimum_turn_minutes                  0.0\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: PNR Remark Level Data.csv\n",
      "record_locator             0\n",
      "pnr_creation_date          0\n",
      "flight_number              0\n",
      "special_service_request    0\n",
      "dtype: int64\n",
      "record_locator             0.0\n",
      "pnr_creation_date          0.0\n",
      "flight_number              0.0\n",
      "special_service_request    0.0\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: PNR+Flight+Level+Data.csv\n",
      "company_id                          0\n",
      "flight_number                       0\n",
      "scheduled_departure_date_local      0\n",
      "scheduled_departure_station_code    0\n",
      "scheduled_arrival_station_code      0\n",
      "record_locator                      0\n",
      "pnr_creation_date                   0\n",
      "total_pax                           0\n",
      "is_child                            0\n",
      "basic_economy_ind                   0\n",
      "is_stroller_user                    0\n",
      "lap_child_count                     0\n",
      "dtype: int64\n",
      "company_id                          0.0\n",
      "flight_number                       0.0\n",
      "scheduled_departure_date_local      0.0\n",
      "scheduled_departure_station_code    0.0\n",
      "scheduled_arrival_station_code      0.0\n",
      "record_locator                      0.0\n",
      "pnr_creation_date                   0.0\n",
      "total_pax                           0.0\n",
      "is_child                            0.0\n",
      "basic_economy_ind                   0.0\n",
      "is_stroller_user                    0.0\n",
      "lap_child_count                     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 2: Define the folder path where your CSV files are\n",
    "folder_path = r\"C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\"\n",
    "\n",
    "# Step 3: List all CSV files in that folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "print(\"CSV files found:\", csv_files)\n",
    "\n",
    "# Step 4: Loop through each CSV file and check for null values\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"\\nChecking nulls for: {file}\")\n",
    "    print(df.isnull().sum())  # shows null counts per column\n",
    "    print(df.isnull().mean() * 100)  # shows % of nulls per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02659031-b06f-4fd2-9edf-5e3a1eb5fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: ['Airports Data.csv', 'Bag+Level+Data.csv', 'Flight Level Data.csv', 'PNR Remark Level Data.csv', 'PNR+Flight+Level+Data.csv']\n",
      "\n",
      "Checking nulls for: Airports Data.csv\n",
      "airport_iata_code     0\n",
      "iso_country_code     15\n",
      "dtype: int64\n",
      "airport_iata_code    0.000000\n",
      "iso_country_code     0.267284\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: Bag+Level+Data.csv\n",
      "company_id                          0\n",
      "flight_number                       0\n",
      "scheduled_departure_date_local      0\n",
      "scheduled_departure_station_code    0\n",
      "scheduled_arrival_station_code      0\n",
      "bag_tag_unique_number               0\n",
      "bag_tag_issue_date                  0\n",
      "bag_type                            0\n",
      "dtype: int64\n",
      "company_id                          0.0\n",
      "flight_number                       0.0\n",
      "scheduled_departure_date_local      0.0\n",
      "scheduled_departure_station_code    0.0\n",
      "scheduled_arrival_station_code      0.0\n",
      "bag_tag_unique_number               0.0\n",
      "bag_tag_issue_date                  0.0\n",
      "bag_type                            0.0\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: Flight Level Data.csv\n",
      "company_id                            0\n",
      "flight_number                         0\n",
      "scheduled_departure_date_local        0\n",
      "scheduled_departure_station_code      0\n",
      "scheduled_arrival_station_code        0\n",
      "scheduled_departure_datetime_local    0\n",
      "scheduled_arrival_datetime_local      0\n",
      "actual_departure_datetime_local       0\n",
      "actual_arrival_datetime_local         0\n",
      "total_seats                           0\n",
      "fleet_type                            0\n",
      "carrier                               0\n",
      "scheduled_ground_time_minutes         0\n",
      "actual_ground_time_minutes            0\n",
      "minimum_turn_minutes                  0\n",
      "dtype: int64\n",
      "company_id                            0.0\n",
      "flight_number                         0.0\n",
      "scheduled_departure_date_local        0.0\n",
      "scheduled_departure_station_code      0.0\n",
      "scheduled_arrival_station_code        0.0\n",
      "scheduled_departure_datetime_local    0.0\n",
      "scheduled_arrival_datetime_local      0.0\n",
      "actual_departure_datetime_local       0.0\n",
      "actual_arrival_datetime_local         0.0\n",
      "total_seats                           0.0\n",
      "fleet_type                            0.0\n",
      "carrier                               0.0\n",
      "scheduled_ground_time_minutes         0.0\n",
      "actual_ground_time_minutes            0.0\n",
      "minimum_turn_minutes                  0.0\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: PNR Remark Level Data.csv\n",
      "record_locator             0\n",
      "pnr_creation_date          0\n",
      "flight_number              0\n",
      "special_service_request    0\n",
      "dtype: int64\n",
      "record_locator             0.0\n",
      "pnr_creation_date          0.0\n",
      "flight_number              0.0\n",
      "special_service_request    0.0\n",
      "dtype: float64\n",
      "\n",
      "Checking nulls for: PNR+Flight+Level+Data.csv\n",
      "company_id                          0\n",
      "flight_number                       0\n",
      "scheduled_departure_date_local      0\n",
      "scheduled_departure_station_code    0\n",
      "scheduled_arrival_station_code      0\n",
      "record_locator                      0\n",
      "pnr_creation_date                   0\n",
      "total_pax                           0\n",
      "is_child                            0\n",
      "basic_economy_ind                   0\n",
      "is_stroller_user                    0\n",
      "lap_child_count                     0\n",
      "dtype: int64\n",
      "company_id                          0.0\n",
      "flight_number                       0.0\n",
      "scheduled_departure_date_local      0.0\n",
      "scheduled_departure_station_code    0.0\n",
      "scheduled_arrival_station_code      0.0\n",
      "record_locator                      0.0\n",
      "pnr_creation_date                   0.0\n",
      "total_pax                           0.0\n",
      "is_child                            0.0\n",
      "basic_economy_ind                   0.0\n",
      "is_stroller_user                    0.0\n",
      "lap_child_count                     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Step 2: Define the folder path where your CSV files are\n",
    "folder_path = r\"C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\"\n",
    "\n",
    "# Step 3: List all CSV files in that folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "print(\"CSV files found:\", csv_files)\n",
    "\n",
    "# Step 4: Loop through each CSV file and check for null values\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"\\nChecking nulls for: {file}\")\n",
    "    print(df.isnull().sum())  # shows null counts per column\n",
    "    print(df.isnull().mean() * 100)  # shows % of nulls per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a99ced8-bc03-447f-99b7-3b68c478bd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers in Airports Data.csv:\n",
      "{}\n",
      "\n",
      "Outliers in Bag+Level+Data.csv:\n",
      "{'flight_number': 76622}\n",
      "\n",
      "Outliers in Flight Level Data.csv:\n",
      "{'flight_number': 0, 'total_seats': 0, 'scheduled_ground_time_minutes': 1529, 'actual_ground_time_minutes': 1215, 'minimum_turn_minutes': 369}\n",
      "\n",
      "Outliers in PNR Remark Level Data.csv:\n",
      "{'flight_number': 760}\n",
      "\n",
      "Outliers in PNR+Flight+Level+Data.csv:\n",
      "{'flight_number': 80665, 'total_pax': 45132, 'basic_economy_ind': 82080, 'lap_child_count': 5588}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Folder path\n",
    "folder_path = r\"C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\"\n",
    "\n",
    "# List CSV files\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers(df):\n",
    "    outlier_info = {}\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        outlier_info[col] = len(outliers)\n",
    "    return outlier_info\n",
    "\n",
    "# Loop through files\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(folder_path, file))\n",
    "    print(f\"\\nOutliers in {file}:\")\n",
    "    print(detect_outliers(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84599ae0-9932-4195-9a5f-0be341e63e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example: Visualize outliers for each numeric column in the first CSV file\n",
    "df = pd.read_csv(os.path.join(folder_path, csv_files[0]))\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot for {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3eda037-c1f5-45ce-a7ea-fb75466c0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example: Visualize outliers for each numeric column in the first CSV file\n",
    "df = pd.read_csv(os.path.join(folder_path, csv_files[0]))\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Boxplot for {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db37e18d-8e8d-4144-9b3b-469ef8b9b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "folder_path = r\"C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\"\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder_path, csv_files[0]))\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.boxplot(x=df[col].dropna())\n",
    "    plt.title(f\"Boxplot for {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9439fb8-6ef9-4bd2-8218-2d52232b3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\flight_level_info.csv'\n",
    "print(os.path.exists(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4112a8f6-bc85-4b83-894e-20d1d73e4afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_id  flight_number scheduled_departure_date_local  \\\n",
      "0         OO           4792                     2025-08-04   \n",
      "1         UA            920                     2025-08-03   \n",
      "2         UA           1776                     2025-08-10   \n",
      "3         OO           5790                     2025-08-06   \n",
      "4         UA           1398                     2025-08-05   \n",
      "\n",
      "  scheduled_departure_station_code scheduled_arrival_station_code  \\\n",
      "0                              ORD                            ROA   \n",
      "1                              ORD                            LHR   \n",
      "2                              ORD                            PHL   \n",
      "3                              ORD                            CRW   \n",
      "4                              ORD                            ATL   \n",
      "\n",
      "  scheduled_departure_datetime_local scheduled_arrival_datetime_local  \\\n",
      "0          2025-08-04 17:57:00+00:00             2025-08-04T21:04:00Z   \n",
      "1          2025-08-03 18:05:00+00:00             2025-08-04T08:20:00Z   \n",
      "2          2025-08-10 18:20:00+00:00             2025-08-10T21:35:00Z   \n",
      "3          2025-08-06 18:20:00+00:00             2025-08-06T21:04:00Z   \n",
      "4          2025-08-05 18:20:00+00:00             2025-08-05T21:29:00Z   \n",
      "\n",
      "  actual_departure_datetime_local actual_arrival_datetime_local  total_seats  \\\n",
      "0       2025-08-04 18:04:00+00:00          2025-08-04T20:52:00Z           76   \n",
      "1       2025-08-03 18:27:00+00:00          2025-08-04T08:06:00Z          167   \n",
      "2       2025-08-10 20:11:00+00:00          2025-08-10T23:26:00Z          166   \n",
      "3       2025-08-06 20:05:00+00:00          2025-08-06T22:42:00Z           50   \n",
      "4       2025-08-05 18:16:00+00:00          2025-08-05T21:49:00Z          166   \n",
      "\n",
      "  fleet_type   carrier  scheduled_ground_time_minutes  \\\n",
      "0    ERJ-175   Express                             42   \n",
      "1   B767-300  Mainline                            235   \n",
      "2   B737-800  Mainline                             76   \n",
      "3    CRJ-200   Express                            223   \n",
      "4   B737-800  Mainline                             75   \n",
      "\n",
      "   actual_ground_time_minutes  minimum_turn_minutes  \n",
      "0                          34                    34  \n",
      "1                         229                   145  \n",
      "2                          69                    51  \n",
      "3                          38                    29  \n",
      "4                          72                    51  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full path with raw string\n",
    "flights = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "                      parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local'])\n",
    "\n",
    "# Quick check\n",
    "print(flights.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529fb38a-6e41-42df-9294-7fe878cded89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_id  flight_number scheduled_departure_date_local  \\\n",
      "0         OO           4792                     2025-08-04   \n",
      "1         UA            920                     2025-08-03   \n",
      "2         UA           1776                     2025-08-10   \n",
      "3         OO           5790                     2025-08-06   \n",
      "4         UA           1398                     2025-08-05   \n",
      "\n",
      "  scheduled_departure_station_code scheduled_arrival_station_code  \\\n",
      "0                              ORD                            ROA   \n",
      "1                              ORD                            LHR   \n",
      "2                              ORD                            PHL   \n",
      "3                              ORD                            CRW   \n",
      "4                              ORD                            ATL   \n",
      "\n",
      "  scheduled_departure_datetime_local scheduled_arrival_datetime_local  \\\n",
      "0          2025-08-04 17:57:00+00:00             2025-08-04T21:04:00Z   \n",
      "1          2025-08-03 18:05:00+00:00             2025-08-04T08:20:00Z   \n",
      "2          2025-08-10 18:20:00+00:00             2025-08-10T21:35:00Z   \n",
      "3          2025-08-06 18:20:00+00:00             2025-08-06T21:04:00Z   \n",
      "4          2025-08-05 18:20:00+00:00             2025-08-05T21:29:00Z   \n",
      "\n",
      "  actual_departure_datetime_local actual_arrival_datetime_local  total_seats  \\\n",
      "0       2025-08-04 18:04:00+00:00          2025-08-04T20:52:00Z           76   \n",
      "1       2025-08-03 18:27:00+00:00          2025-08-04T08:06:00Z          167   \n",
      "2       2025-08-10 20:11:00+00:00          2025-08-10T23:26:00Z          166   \n",
      "3       2025-08-06 20:05:00+00:00          2025-08-06T22:42:00Z           50   \n",
      "4       2025-08-05 18:16:00+00:00          2025-08-05T21:49:00Z          166   \n",
      "\n",
      "  fleet_type   carrier  scheduled_ground_time_minutes  \\\n",
      "0    ERJ-175   Express                             42   \n",
      "1   B767-300  Mainline                            235   \n",
      "2   B737-800  Mainline                             76   \n",
      "3    CRJ-200   Express                            223   \n",
      "4   B737-800  Mainline                             75   \n",
      "\n",
      "   actual_ground_time_minutes  minimum_turn_minutes  \n",
      "0                          34                    34  \n",
      "1                         229                   145  \n",
      "2                          69                    51  \n",
      "3                          38                    29  \n",
      "4                          72                    51  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full path with raw string\n",
    "flights = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "                      parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local'])\n",
    "\n",
    "# Quick check\n",
    "print(flights.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345cbcdb-ebde-46fa-8d04-e14163c835ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_id  flight_number scheduled_departure_date_local  \\\n",
      "0         OO           4792                     2025-08-04   \n",
      "1         UA            920                     2025-08-03   \n",
      "2         UA           1776                     2025-08-10   \n",
      "3         OO           5790                     2025-08-06   \n",
      "4         UA           1398                     2025-08-05   \n",
      "\n",
      "  scheduled_departure_station_code scheduled_arrival_station_code  \\\n",
      "0                              ORD                            ROA   \n",
      "1                              ORD                            LHR   \n",
      "2                              ORD                            PHL   \n",
      "3                              ORD                            CRW   \n",
      "4                              ORD                            ATL   \n",
      "\n",
      "  scheduled_departure_datetime_local scheduled_arrival_datetime_local  \\\n",
      "0          2025-08-04 17:57:00+00:00             2025-08-04T21:04:00Z   \n",
      "1          2025-08-03 18:05:00+00:00             2025-08-04T08:20:00Z   \n",
      "2          2025-08-10 18:20:00+00:00             2025-08-10T21:35:00Z   \n",
      "3          2025-08-06 18:20:00+00:00             2025-08-06T21:04:00Z   \n",
      "4          2025-08-05 18:20:00+00:00             2025-08-05T21:29:00Z   \n",
      "\n",
      "  actual_departure_datetime_local actual_arrival_datetime_local  total_seats  \\\n",
      "0       2025-08-04 18:04:00+00:00          2025-08-04T20:52:00Z           76   \n",
      "1       2025-08-03 18:27:00+00:00          2025-08-04T08:06:00Z          167   \n",
      "2       2025-08-10 20:11:00+00:00          2025-08-10T23:26:00Z          166   \n",
      "3       2025-08-06 20:05:00+00:00          2025-08-06T22:42:00Z           50   \n",
      "4       2025-08-05 18:16:00+00:00          2025-08-05T21:49:00Z          166   \n",
      "\n",
      "  fleet_type   carrier  scheduled_ground_time_minutes  \\\n",
      "0    ERJ-175   Express                             42   \n",
      "1   B767-300  Mainline                            235   \n",
      "2   B737-800  Mainline                             76   \n",
      "3    CRJ-200   Express                            223   \n",
      "4   B737-800  Mainline                             75   \n",
      "\n",
      "   actual_ground_time_minutes  minimum_turn_minutes  \n",
      "0                          34                    34  \n",
      "1                         229                   145  \n",
      "2                          69                    51  \n",
      "3                          38                    29  \n",
      "4                          72                    51  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full path with raw string\n",
    "flights = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "                      parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local'])\n",
    "\n",
    "# Quick check\n",
    "print(flights.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2432c7-6fac-4cd8-9167-82d048b75f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_id  flight_number scheduled_departure_date_local  \\\n",
      "0         OO           4792                     2025-08-04   \n",
      "1         UA            920                     2025-08-03   \n",
      "2         UA           1776                     2025-08-10   \n",
      "3         OO           5790                     2025-08-06   \n",
      "4         UA           1398                     2025-08-05   \n",
      "\n",
      "  scheduled_departure_station_code scheduled_arrival_station_code  \\\n",
      "0                              ORD                            ROA   \n",
      "1                              ORD                            LHR   \n",
      "2                              ORD                            PHL   \n",
      "3                              ORD                            CRW   \n",
      "4                              ORD                            ATL   \n",
      "\n",
      "  scheduled_departure_datetime_local scheduled_arrival_datetime_local  \\\n",
      "0          2025-08-04 17:57:00+00:00             2025-08-04T21:04:00Z   \n",
      "1          2025-08-03 18:05:00+00:00             2025-08-04T08:20:00Z   \n",
      "2          2025-08-10 18:20:00+00:00             2025-08-10T21:35:00Z   \n",
      "3          2025-08-06 18:20:00+00:00             2025-08-06T21:04:00Z   \n",
      "4          2025-08-05 18:20:00+00:00             2025-08-05T21:29:00Z   \n",
      "\n",
      "  actual_departure_datetime_local actual_arrival_datetime_local  total_seats  \\\n",
      "0       2025-08-04 18:04:00+00:00          2025-08-04T20:52:00Z           76   \n",
      "1       2025-08-03 18:27:00+00:00          2025-08-04T08:06:00Z          167   \n",
      "2       2025-08-10 20:11:00+00:00          2025-08-10T23:26:00Z          166   \n",
      "3       2025-08-06 20:05:00+00:00          2025-08-06T22:42:00Z           50   \n",
      "4       2025-08-05 18:16:00+00:00          2025-08-05T21:49:00Z          166   \n",
      "\n",
      "  fleet_type   carrier  scheduled_ground_time_minutes  \\\n",
      "0    ERJ-175   Express                             42   \n",
      "1   B767-300  Mainline                            235   \n",
      "2   B737-800  Mainline                             76   \n",
      "3    CRJ-200   Express                            223   \n",
      "4   B737-800  Mainline                             75   \n",
      "\n",
      "   actual_ground_time_minutes  minimum_turn_minutes  \n",
      "0                          34                    34  \n",
      "1                         229                   145  \n",
      "2                          69                    51  \n",
      "3                          38                    29  \n",
      "4                          72                    51  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full path with raw string\n",
    "flights = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "                      parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local'])\n",
    "\n",
    "# Quick check\n",
    "print(flights.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c53a1a2-4c36-4626-91a2-92bbbf792e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_id  flight_number scheduled_departure_date_local  \\\n",
      "0         OO           4792                     2025-08-04   \n",
      "1         UA            920                     2025-08-03   \n",
      "2         UA           1776                     2025-08-10   \n",
      "3         OO           5790                     2025-08-06   \n",
      "4         UA           1398                     2025-08-05   \n",
      "\n",
      "  scheduled_departure_station_code scheduled_arrival_station_code  \\\n",
      "0                              ORD                            ROA   \n",
      "1                              ORD                            LHR   \n",
      "2                              ORD                            PHL   \n",
      "3                              ORD                            CRW   \n",
      "4                              ORD                            ATL   \n",
      "\n",
      "  scheduled_departure_datetime_local scheduled_arrival_datetime_local  \\\n",
      "0          2025-08-04 17:57:00+00:00             2025-08-04T21:04:00Z   \n",
      "1          2025-08-03 18:05:00+00:00             2025-08-04T08:20:00Z   \n",
      "2          2025-08-10 18:20:00+00:00             2025-08-10T21:35:00Z   \n",
      "3          2025-08-06 18:20:00+00:00             2025-08-06T21:04:00Z   \n",
      "4          2025-08-05 18:20:00+00:00             2025-08-05T21:29:00Z   \n",
      "\n",
      "  actual_departure_datetime_local actual_arrival_datetime_local  total_seats  \\\n",
      "0       2025-08-04 18:04:00+00:00          2025-08-04T20:52:00Z           76   \n",
      "1       2025-08-03 18:27:00+00:00          2025-08-04T08:06:00Z          167   \n",
      "2       2025-08-10 20:11:00+00:00          2025-08-10T23:26:00Z          166   \n",
      "3       2025-08-06 20:05:00+00:00          2025-08-06T22:42:00Z           50   \n",
      "4       2025-08-05 18:16:00+00:00          2025-08-05T21:49:00Z          166   \n",
      "\n",
      "  fleet_type   carrier  scheduled_ground_time_minutes  \\\n",
      "0    ERJ-175   Express                             42   \n",
      "1   B767-300  Mainline                            235   \n",
      "2   B737-800  Mainline                             76   \n",
      "3    CRJ-200   Express                            223   \n",
      "4   B737-800  Mainline                             75   \n",
      "\n",
      "   actual_ground_time_minutes  minimum_turn_minutes  \n",
      "0                          34                    34  \n",
      "1                         229                   145  \n",
      "2                          69                    51  \n",
      "3                          38                    29  \n",
      "4                          72                    51  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Full path with raw string\n",
    "flights = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "                      parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local'])\n",
    "\n",
    "# Quick check\n",
    "print(flights.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46e642a0-2a1e-45fb-a5fe-8d43a2322274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average delay: 21.18 mins, % late flights: 49.61%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV with the full path\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "flights['departure_delay_mins'] = (\n",
    "    flights['actual_departure_datetime_local'] - flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Average delay\n",
    "avg_delay = flights['departure_delay_mins'].mean()\n",
    "\n",
    "# % of flights departing late\n",
    "pct_late = (flights['departure_delay_mins'] > 0).mean() * 100\n",
    "\n",
    "print(f\"Average delay: {avg_delay:.2f} mins, % late flights: {pct_late:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a42dd3-2a17-4779-b566-c121f4e2892b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average delay (UA flights): 22.29 mins\n",
      "% of late flights (UA flights): 54.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\4181206723.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Average delay\n",
    "avg_delay = ua_flights['departure_delay_mins'].mean()\n",
    "\n",
    "# % of flights departing late\n",
    "pct_late = (ua_flights['departure_delay_mins'] > 0).mean() * 100\n",
    "\n",
    "print(f\"Average delay (UA flights): {avg_delay:.2f} mins\")\n",
    "print(f\"% of late flights (UA flights): {pct_late:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf9c890-e97b-4390-a329-ac9a0a89d493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       92.600000\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "244           2133       81.200000\n",
      "38             534       72.800000\n",
      "132           1335       70.846154\n",
      "296           2426       70.733333\n",
      "74             845       67.933333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\963879143.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Average delay per flight number\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Show top 10 flights with highest average delay\n",
    "print(avg_delay_per_flight.sort_values(by='avg_delay_mins', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7b2b81-f5d9-4c32-b81a-78e0b219152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       92.600000\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "244           2133       81.200000\n",
      "38             534       72.800000\n",
      "132           1335       70.846154\n",
      "296           2426       70.733333\n",
      "74             845       67.933333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\963879143.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Average delay per flight number\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Show top 10 flights with highest average delay\n",
    "print(avg_delay_per_flight.sort_values(by='avg_delay_mins', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8c5e4a-917f-469f-937f-e8168756e93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       92.600000\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "100           1120       -5.750000\n",
      "213           1921       -6.000000\n",
      "208           1879       -6.000000\n",
      "55             669       -6.111111\n",
      "16             342       -7.000000\n",
      "\n",
      "[331 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1643943907.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Average delay per flight number\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Sort all flights by average delay (descending)\n",
    "all_avg_delayed_flights = avg_delay_per_flight.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad4d724-693e-4f74-bb28-103e19f6af9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       92.600000\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "100           1120       -5.750000\n",
      "213           1921       -6.000000\n",
      "208           1879       -6.000000\n",
      "55             669       -6.111111\n",
      "16             342       -7.000000\n",
      "\n",
      "[331 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1643943907.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Average delay per flight number\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Sort all flights by average delay (descending)\n",
    "all_avg_delayed_flights = avg_delay_per_flight.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bc1980b-9b51-4bfb-9e9c-7a360462546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       93.133333\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "2              202        0.000000\n",
      "208           1879        0.000000\n",
      "55             669        0.000000\n",
      "48             604        0.000000\n",
      "104           1135        0.000000\n",
      "\n",
      "[331 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\3855228256.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n",
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\3855228256.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Replace negative delays with NaN so they don't affect the mean\n",
    "ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n",
    "\n",
    "# Average delay per flight number (ignoring negative values)\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins_nonneg'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins_nonneg': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Remove any flights with negative or NaN average delay (just in case)\n",
    "all_avg_delayed_flights = avg_delay_per_flight[avg_delay_per_flight['avg_delay_mins'] >= 0]\n",
    "\n",
    "# Sort by average delay descending\n",
    "all_avg_delayed_flights = all_avg_delayed_flights.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c55ddf5f-09a0-4116-97df-da38b52e8445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       93.133333\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "118           1252        0.400000\n",
      "318           2653        0.333333\n",
      "284           2369        0.266667\n",
      "291           2401        0.250000\n",
      "323           2666        0.133333\n",
      "\n",
      "[316 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1341050448.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n",
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1341050448.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Replace negative delays with 0 so they don't affect the mean\n",
    "ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n",
    "\n",
    "# Average delay per flight number (ignoring negative values)\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins_nonneg'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins_nonneg': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Keep only flights with positive average delay\n",
    "all_avg_delayed_flights = avg_delay_per_flight[avg_delay_per_flight['avg_delay_mins'] > 0]\n",
    "\n",
    "# Sort by average delay descending\n",
    "all_avg_delayed_flights = all_avg_delayed_flights.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1c3a954-efa6-47ca-a0a1-7353e4a1af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       93.133333\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "118           1252        0.400000\n",
      "318           2653        0.333333\n",
      "284           2369        0.266667\n",
      "291           2401        0.250000\n",
      "323           2666        0.133333\n",
      "\n",
      "[316 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1341050448.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n",
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1341050448.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Replace negative delays with 0 so they don't affect the mean\n",
    "ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n",
    "\n",
    "# Average delay per flight number (ignoring negative values)\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins_nonneg'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins_nonneg': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Keep only flights with positive average delay\n",
    "all_avg_delayed_flights = avg_delay_per_flight[avg_delay_per_flight['avg_delay_mins'] > 0]\n",
    "\n",
    "# Sort by average delay descending\n",
    "all_avg_delayed_flights = all_avg_delayed_flights.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "439312e2-1c8a-4ad8-aa4e-503f1cd9b55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       93.133333\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "118           1252        0.400000\n",
      "318           2653        0.333333\n",
      "284           2369        0.266667\n",
      "291           2401        0.250000\n",
      "323           2666        0.133333\n",
      "\n",
      "[316 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1341050448.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n",
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1341050448.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Replace negative delays with 0 so they don't affect the mean\n",
    "ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n",
    "\n",
    "# Average delay per flight number (ignoring negative values)\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins_nonneg'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins_nonneg': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Keep only flights with positive average delay\n",
    "all_avg_delayed_flights = avg_delay_per_flight[avg_delay_per_flight['avg_delay_mins'] > 0]\n",
    "\n",
    "# Sort by average delay descending\n",
    "all_avg_delayed_flights = all_avg_delayed_flights.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b016df-8ebd-4f39-98c8-4e058aea2bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Flight_Level_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read relevant columns including company_id\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m flights \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFlight_Level_Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight_number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduled_ground_time_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimum_turn_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Filter for United Airlines only\u001b[39;00m\n\u001b[0;32m     10\u001b[0m ua_flights \u001b[38;5;241m=\u001b[39m flights[flights[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Flight_Level_Data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read relevant columns including company_id\n",
    "flights = pd.read_csv(\n",
    "    r'Flight_Level_Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate difference between scheduled ground time and minimum turn\n",
    "ua_flights['ground_vs_min_turn'] = ua_flights['scheduled_ground_time_minutes'] - ua_flights['minimum_turn_minutes']\n",
    "\n",
    "# Data-driven threshold: define \"close\" as the 10th percentile\n",
    "threshold = ua_flights['ground_vs_min_turn'].quantile(0.10)\n",
    "\n",
    "# Filter flights that are close to or below minimum turn\n",
    "critical_flights = ua_flights[ua_flights['ground_vs_min_turn'] <= threshold]\n",
    "\n",
    "# Count number of such flights\n",
    "num_critical = critical_flights['flight_number'].nunique()\n",
    "print(f\"Number of UA flights close to or below minimum turn: {num_critical}\")\n",
    "\n",
    "# Optional: see top 10 tightest flights\n",
    "print(critical_flights.nsmallest(10, 'ground_vs_min_turn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75f0299a-96fa-4544-8922-5d92066894f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UA flights close to or below minimum turn: 219\n",
      "     company_id  flight_number  scheduled_ground_time_minutes  \\\n",
      "5885         UA           2278                           -250   \n",
      "7123         UA           2278                           -240   \n",
      "5898         UA            793                           -195   \n",
      "959          UA            247                           -249   \n",
      "2435         UA           2039                           -222   \n",
      "2457         UA           1834                           -223   \n",
      "1302         UA           1899                           -183   \n",
      "3598         UA            777                           -197   \n",
      "7083         UA           1710                           -193   \n",
      "5124         UA           2133                           -180   \n",
      "\n",
      "      minimum_turn_minutes  ground_vs_min_turn  \n",
      "5885                    62                -312  \n",
      "7123                    70                -310  \n",
      "5898                   110                -305  \n",
      "959                     46                -295  \n",
      "2435                    62                -284  \n",
      "2457                    51                -274  \n",
      "1302                    70                -253  \n",
      "3598                    56                -253  \n",
      "7083                    56                -249  \n",
      "5124                    56                -236  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\2798049456.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['ground_vs_min_turn'] = ua_flights['scheduled_ground_time_minutes'] - ua_flights['minimum_turn_minutes']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read relevant columns including company_id\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate difference between scheduled ground time and minimum turn\n",
    "ua_flights['ground_vs_min_turn'] = ua_flights['scheduled_ground_time_minutes'] - ua_flights['minimum_turn_minutes']\n",
    "\n",
    "# Data-driven threshold: define \"close\" as the 10th percentile\n",
    "threshold = ua_flights['ground_vs_min_turn'].quantile(0.10)\n",
    "\n",
    "# Filter flights that are close to or below minimum turn\n",
    "critical_flights = ua_flights[ua_flights['ground_vs_min_turn'] <= threshold]\n",
    "\n",
    "# Count number of such flights\n",
    "num_critical = critical_flights['flight_number'].nunique()\n",
    "print(f\"Number of UA flights close to or below minimum turn: {num_critical}\")\n",
    "\n",
    "# Optional: see top 10 tightest flights\n",
    "print(critical_flights.nsmallest(10, 'ground_vs_min_turn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b268ed22-1920-4550-b013-cd3356748307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  avg_delay_mins\n",
      "76             907       95.200000\n",
      "251           2155       93.600000\n",
      "79             920       93.133333\n",
      "156           1564       84.533333\n",
      "150           1492       83.800000\n",
      "..             ...             ...\n",
      "118           1252        0.400000\n",
      "318           2653        0.333333\n",
      "284           2369        0.266667\n",
      "291           2401        0.250000\n",
      "323           2666        0.133333\n",
      "\n",
      "[316 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1225462882.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins'] = (\n",
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1225462882.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    parse_dates=['scheduled_departure_datetime_local', 'actual_departure_datetime_local']\n",
    ")\n",
    "\n",
    "# Filter only United Airlines flights\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Calculate departure delay in minutes\n",
    "ua_flights['departure_delay_mins'] = (\n",
    "    ua_flights['actual_departure_datetime_local'] - ua_flights['scheduled_departure_datetime_local']\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Replace negative delays with 0 so they don't affect the mean\n",
    "ua_flights['departure_delay_mins_nonneg'] = ua_flights['departure_delay_mins'].clip(lower=0)\n",
    "\n",
    "# Average delay per flight number (ignoring negative values)\n",
    "avg_delay_per_flight = ua_flights.groupby('flight_number')['departure_delay_mins_nonneg'].mean().reset_index()\n",
    "\n",
    "# Rename column for clarity\n",
    "avg_delay_per_flight.rename(columns={'departure_delay_mins_nonneg': 'avg_delay_mins'}, inplace=True)\n",
    "\n",
    "# Keep only flights with positive average delay\n",
    "all_avg_delayed_flights = avg_delay_per_flight[avg_delay_per_flight['avg_delay_mins'] > 0]\n",
    "\n",
    "# Sort by average delay descending\n",
    "all_avg_delayed_flights = all_avg_delayed_flights.sort_values(by='avg_delay_mins', ascending=False)\n",
    "\n",
    "# Display all flights with their average delay\n",
    "print(all_avg_delayed_flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eda76944-a2ed-4c7e-8b7f-d6ca6f220ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flight_number  positive_percentage\n",
      "0                3            60.000000\n",
      "1              118            40.000000\n",
      "2              202           100.000000\n",
      "3              219            53.333333\n",
      "4              224            53.333333\n",
      "..             ...                  ...\n",
      "326           2683            46.666667\n",
      "327           2684            66.666667\n",
      "328           2691            23.076923\n",
      "329           2862            60.000000\n",
      "330           2865            58.333333\n",
      "\n",
      "[329 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\989635874.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  percentage_df = flights.groupby('flight_number').apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read only the required columns\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\UPDATED\\Flight Level Data UPDATED.csv',\n",
    "    usecols=['flight_number', 'diff of R1-Q1']\n",
    ")\n",
    "\n",
    "# Calculate percentage of positive 'diff of R1-Q1' per flight using all rows\n",
    "percentage_df = flights.groupby('flight_number').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'positive_percentage': (x['diff of R1-Q1'] > 0).sum() / len(x) * 100\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Keep only flights with percentage > 0 (i.e., at least one positive diff)\n",
    "percentage_df = percentage_df[percentage_df['positive_percentage'] > 0]\n",
    "\n",
    "# Sort by flight_number in ascending order\n",
    "percentage_df = percentage_df.sort_values(by='flight_number', ascending=True)\n",
    "\n",
    "# Preview\n",
    "print(percentage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5963e0e-eb03-4bda-bd1e-f29b1e224403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UA flights close to or below minimum turn: 185\n",
      "     company_id  flight_number  scheduled_ground_time_minutes  \\\n",
      "5641         UA            920                             45   \n",
      "3191         UA           2113                             28   \n",
      "4198         UA           1983                             28   \n",
      "3721         UA           1182                             20   \n",
      "3969         UA            739                             24   \n",
      "558          UA            881                             20   \n",
      "6363         UA            881                             20   \n",
      "5986         UA           2113                             40   \n",
      "1150         UA           1270                              3   \n",
      "5835         UA           1659                              3   \n",
      "\n",
      "      minimum_turn_minutes  ground_vs_min_turn  \n",
      "5641                   145                -100  \n",
      "3191                   119                 -91  \n",
      "4198                   119                 -91  \n",
      "3721                   110                 -90  \n",
      "3969                   110                 -86  \n",
      "558                    100                 -80  \n",
      "6363                   100                 -80  \n",
      "5986                   119                 -79  \n",
      "1150                    70                 -67  \n",
      "5835                    70                 -67  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read relevant columns including company_id\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_flights = flights[flights['company_id'] == 'UA']\n",
    "\n",
    "# Remove invalid or negative ground times\n",
    "ua_flights = ua_flights[ua_flights['scheduled_ground_time_minutes'] > 0]\n",
    "\n",
    "# Calculate difference between scheduled ground time and minimum turn\n",
    "ua_flights['ground_vs_min_turn'] = ua_flights['scheduled_ground_time_minutes'] - ua_flights['minimum_turn_minutes']\n",
    "\n",
    "# Data-driven threshold: define \"close\" as the 10th percentile\n",
    "threshold = ua_flights['ground_vs_min_turn'].quantile(0.10)\n",
    "\n",
    "# Filter flights that are close to or below minimum turn\n",
    "critical_flights = ua_flights[ua_flights['ground_vs_min_turn'] <= threshold]\n",
    "\n",
    "# Count number of such flights\n",
    "num_critical = critical_flights['flight_number'].nunique()\n",
    "print(f\"Number of UA flights close to or below minimum turn: {num_critical}\")\n",
    "\n",
    "# Optional: see top 10 tightest flights\n",
    "print(critical_flights.nsmallest(10, 'ground_vs_min_turn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d49b6ef0-f3da-44df-b3d9-4f022032413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UA flights close to or below minimum turn: 185\n",
      "     company_id  flight_number  scheduled_ground_time_minutes  \\\n",
      "5641         UA            920                             45   \n",
      "3191         UA           2113                             28   \n",
      "4198         UA           1983                             28   \n",
      "3721         UA           1182                             20   \n",
      "3969         UA            739                             24   \n",
      "558          UA            881                             20   \n",
      "6363         UA            881                             20   \n",
      "5986         UA           2113                             40   \n",
      "1150         UA           1270                              3   \n",
      "5835         UA           1659                              3   \n",
      "\n",
      "      minimum_turn_minutes  ground_vs_min_turn  \n",
      "5641                   145                -100  \n",
      "3191                   119                 -91  \n",
      "4198                   119                 -91  \n",
      "3721                   110                 -90  \n",
      "3969                   110                 -86  \n",
      "558                    100                 -80  \n",
      "6363                   100                 -80  \n",
      "5986                   119                 -79  \n",
      "1150                    70                 -67  \n",
      "5835                    70                 -67  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read relevant columns\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines and valid data\n",
    "ua_flights = flights[(flights['company_id'] == 'UA') & \n",
    "                     (flights['scheduled_ground_time_minutes'] > 0) &\n",
    "                     (flights['minimum_turn_minutes'] > 0)].copy()\n",
    "\n",
    "# Calculate difference\n",
    "ua_flights['ground_vs_min_turn'] = ua_flights['scheduled_ground_time_minutes'] - ua_flights['minimum_turn_minutes']\n",
    "\n",
    "# Define threshold\n",
    "threshold = ua_flights['ground_vs_min_turn'].quantile(0.10)\n",
    "\n",
    "# Critical flights\n",
    "critical_flights = ua_flights[ua_flights['ground_vs_min_turn'] <= threshold]\n",
    "\n",
    "# Count and inspect\n",
    "num_critical = critical_flights['flight_number'].nunique()\n",
    "print(f\"Number of UA flights close to or below minimum turn: {num_critical}\")\n",
    "print(critical_flights.nsmallest(10, 'ground_vs_min_turn'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3008957-1947-42f9-8a77-3a302b710d03",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\seema\\\\United-Airlines-CaseStudy\\\\Data\\\\raw\\\\Bag Level Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read the Bag Level Information CSV\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m bags \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mseema\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUnited-Airlines-CaseStudy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBag Level Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                    usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight_number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbag_type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Filter for United Airlines only\u001b[39;00m\n\u001b[0;32m      8\u001b[0m ua_bags \u001b[38;5;241m=\u001b[39m bags[bags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\seema\\\\United-Airlines-CaseStudy\\\\Data\\\\raw\\\\Bag Level Data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Bag Level Information CSV\n",
    "bags = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Bag Level Data.csv',\n",
    "                   usecols=['company_id', 'flight_number', 'bag_type'])\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_bags = bags[bags['company_id'] == 'UA']\n",
    "\n",
    "# Group by flight_number and count Checked vs Transfer bags\n",
    "bag_counts = ua_bags.groupby(['flight_number', 'bag_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure both columns exist (Checked and Transfer), add if missing\n",
    "for col in ['Checked', 'Transfer']:\n",
    "    if col not in bag_counts.columns:\n",
    "        bag_counts[col] = 0\n",
    "\n",
    "# Calculate ratio of Transfer / Checked per flight\n",
    "bag_counts['transfer_to_checked_ratio'] = bag_counts['Transfer'] / bag_counts['Checked']\n",
    "\n",
    "# Average ratio across all flights\n",
    "average_ratio = bag_counts['transfer_to_checked_ratio'].mean()\n",
    "\n",
    "print(f\"Average ratio of transfer bags vs checked bags across UA flights: {average_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7b5703b-b70d-4a26-bf25-f4fc5e1e7930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ratio of transfer bags vs checked bags across UA flights: inf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Bag Level Information CSV\n",
    "bags = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Bag+Level+Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'bag_type']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_bags = bags[bags['company_id'] == 'UA']\n",
    "\n",
    "# Group by flight_number and count Checked vs Transfer bags\n",
    "bag_counts = ua_bags.groupby(['flight_number', 'bag_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure both columns exist (Checked and Transfer), add if missing\n",
    "for col in ['Checked', 'Transfer']:\n",
    "    if col not in bag_counts.columns:\n",
    "        bag_counts[col] = 0\n",
    "\n",
    "# Calculate ratio of Transfer / Checked per flight\n",
    "bag_counts['transfer_to_checked_ratio'] = bag_counts['Transfer'] / bag_counts['Checked']\n",
    "\n",
    "# Average ratio across all flights\n",
    "average_ratio = bag_counts['transfer_to_checked_ratio'].mean()\n",
    "\n",
    "print(f\"Average ratio of transfer bags vs checked bags across UA flights: {average_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c75a04c-5f46-49e0-823e-737ed8927433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_type  flight_number  transfer_to_checked_ratio\n",
      "0                     3                        inf\n",
      "1                    60                        inf\n",
      "2                   118                        inf\n",
      "3                   202                        inf\n",
      "4                   205                        inf\n",
      "..                  ...                        ...\n",
      "355                3018                        inf\n",
      "356                3024                        inf\n",
      "357                3025                        inf\n",
      "358                3048                        inf\n",
      "359                3748                        NaN\n",
      "\n",
      "[360 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\1804414613.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  flight_ratios['transfer_to_checked_ratio'] = flight_ratios['transfer_to_checked_ratio'].round(2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Bag Level Information CSV\n",
    "bags = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Bag+Level+Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'bag_type']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_bags = bags[bags['company_id'] == 'UA']\n",
    "\n",
    "# Group by flight_number and count Checked vs Transfer bags\n",
    "bag_counts = ua_bags.groupby(['flight_number', 'bag_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure both columns exist (Checked and Transfer), add if missing\n",
    "for col in ['Checked', 'Transfer']:\n",
    "    if col not in bag_counts.columns:\n",
    "        bag_counts[col] = 0\n",
    "\n",
    "# Calculate ratio of Transfer / Checked per flight\n",
    "bag_counts['transfer_to_checked_ratio'] = bag_counts['Transfer'] / bag_counts['Checked']\n",
    "\n",
    "# Reset index to make flight_number a column\n",
    "bag_counts = bag_counts.reset_index()\n",
    "\n",
    "# Display flight_number and ratio per flight\n",
    "flight_ratios = bag_counts[['flight_number', 'transfer_to_checked_ratio']]\n",
    "\n",
    "# Optional: round ratios to 2 decimal places\n",
    "flight_ratios['transfer_to_checked_ratio'] = flight_ratios['transfer_to_checked_ratio'].round(2)\n",
    "\n",
    "# Print per-flight ratios\n",
    "print(flight_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e43766c3-6232-4f69-a65a-4aa54cde646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_type  flight_number  transfer_to_checked_ratio\n",
      "0                     3                        NaN\n",
      "1                    60                        NaN\n",
      "2                   118                        NaN\n",
      "3                   202                        NaN\n",
      "4                   205                        NaN\n",
      "..                  ...                        ...\n",
      "355                3018                        NaN\n",
      "356                3024                        NaN\n",
      "357                3025                        NaN\n",
      "358                3048                        NaN\n",
      "359                3748                        NaN\n",
      "\n",
      "[360 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema\\AppData\\Local\\Temp\\ipykernel_24444\\4013764348.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  flight_ratios['transfer_to_checked_ratio'] = flight_ratios['transfer_to_checked_ratio'].round(2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the Bag Level Information CSV\n",
    "bags = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Bag+Level+Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'bag_type']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_bags = bags[bags['company_id'] == 'UA']\n",
    "\n",
    "# Group by flight_number and count Checked vs Transfer bags\n",
    "bag_counts = ua_bags.groupby(['flight_number', 'bag_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure both columns exist\n",
    "for col in ['Checked', 'Transfer']:\n",
    "    if col not in bag_counts.columns:\n",
    "        bag_counts[col] = 0\n",
    "\n",
    "# Calculate ratio safely\n",
    "bag_counts['transfer_to_checked_ratio'] = np.where(\n",
    "    bag_counts['Checked'] == 0,\n",
    "    np.nan,  # or 0 if you prefer\n",
    "    bag_counts['Transfer'] / bag_counts['Checked']\n",
    ")\n",
    "\n",
    "# Reset index to make flight_number a column\n",
    "bag_counts = bag_counts.reset_index()\n",
    "\n",
    "# Select relevant columns\n",
    "flight_ratios = bag_counts[['flight_number', 'transfer_to_checked_ratio']]\n",
    "\n",
    "# Optional: round ratios\n",
    "flight_ratios['transfer_to_checked_ratio'] = flight_ratios['transfer_to_checked_ratio'].round(2)\n",
    "\n",
    "print(flight_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffa3f23c-c04d-4987-968a-c737a1596eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_type  flight_number  transfer_to_checked_ratio\n",
      "0                     3                       1.31\n",
      "1                    60                        NaN\n",
      "2                   118                       1.31\n",
      "3                   202                       0.45\n",
      "4                   205                        NaN\n",
      "..                  ...                        ...\n",
      "355                3018                       0.02\n",
      "356                3024                       0.37\n",
      "357                3025                       0.70\n",
      "358                3048                       0.15\n",
      "359                3748                       0.00\n",
      "\n",
      "[360 rows x 2 columns]\n",
      "\n",
      "Overall average ratio across all flights: 1.99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the Bag Level Information CSV\n",
    "bags = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Bag+Level+Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'bag_type']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_bags = bags[bags['company_id'] == 'UA'].copy()\n",
    "\n",
    "# Clean and standardize bag_type\n",
    "ua_bags['bag_type'] = ua_bags['bag_type'].str.strip().str.lower()\n",
    "\n",
    "# Group by flight_number and count each bag_type\n",
    "bag_counts = ua_bags.groupby(['flight_number', 'bag_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure all three columns exist\n",
    "for col in ['origin', 'transfer', 'hot transfer']:\n",
    "    if col not in bag_counts.columns:\n",
    "        bag_counts[col] = 0\n",
    "\n",
    "# Total transfer bags = transfer + hot transfer\n",
    "bag_counts['total_transfer'] = bag_counts['transfer'] + bag_counts['hot transfer']\n",
    "\n",
    "# Treat 'origin' as 'checked'\n",
    "bag_counts['checked'] = bag_counts['origin']\n",
    "\n",
    "# Calculate ratio safely\n",
    "bag_counts['transfer_to_checked_ratio'] = np.where(\n",
    "    bag_counts['checked'] == 0,\n",
    "    np.nan,\n",
    "    bag_counts['total_transfer'] / bag_counts['checked']\n",
    ")\n",
    "\n",
    "# Reset index\n",
    "bag_counts = bag_counts.reset_index()\n",
    "\n",
    "# Round ratios\n",
    "bag_counts['transfer_to_checked_ratio'] = bag_counts['transfer_to_checked_ratio'].round(2)\n",
    "\n",
    "# Print per-flight ratios\n",
    "print(bag_counts[['flight_number', 'transfer_to_checked_ratio']])\n",
    "\n",
    "# Overall average ratio\n",
    "overall_avg_ratio = bag_counts['transfer_to_checked_ratio'].mean()\n",
    "print(f\"\\nOverall average ratio across all flights: {overall_avg_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b043f05-0da2-45cd-bc6b-50401e5b311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UA flights close to or below minimum turn: 185\n",
      "     company_id  flight_number  scheduled_ground_time_minutes  \\\n",
      "5641         UA            920                             45   \n",
      "3191         UA           2113                             28   \n",
      "4198         UA           1983                             28   \n",
      "3721         UA           1182                             20   \n",
      "3969         UA            739                             24   \n",
      "558          UA            881                             20   \n",
      "6363         UA            881                             20   \n",
      "5986         UA           2113                             40   \n",
      "1150         UA           1270                              3   \n",
      "5835         UA           1659                              3   \n",
      "\n",
      "      minimum_turn_minutes  ground_vs_min_turn  \n",
      "5641                   145                -100  \n",
      "3191                   119                 -91  \n",
      "4198                   119                 -91  \n",
      "3721                   110                 -90  \n",
      "3969                   110                 -86  \n",
      "558                    100                 -80  \n",
      "6363                   100                 -80  \n",
      "5986                   119                 -79  \n",
      "1150                    70                 -67  \n",
      "5835                    70                 -67  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read relevant columns\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines and valid data\n",
    "ua_flights = flights[(flights['company_id'] == 'UA') & \n",
    "                     (flights['scheduled_ground_time_minutes'] > 0) &\n",
    "                     (flights['minimum_turn_minutes'] > 0)].copy()\n",
    "\n",
    "# Calculate difference\n",
    "ua_flights['ground_vs_min_turn'] = ua_flights['scheduled_ground_time_minutes'] - ua_flights['minimum_turn_minutes']\n",
    "\n",
    "# Define threshold\n",
    "threshold = ua_flights['ground_vs_min_turn'].quantile(0.10)\n",
    "\n",
    "# Critical flights\n",
    "critical_flights = ua_flights[ua_flights['ground_vs_min_turn'] <= threshold]\n",
    "\n",
    "# Count and inspect\n",
    "num_critical = critical_flights['flight_number'].nunique()\n",
    "print(f\"Number of UA flights close to or below minimum turn: {num_critical}\")\n",
    "print(critical_flights.nsmallest(10, 'ground_vs_min_turn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba93fccc-6645-43d2-84bc-e4322e717dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of UA flights with scheduled ground time close to or below minimum turn: 182\n",
      "    company_id  flight_number  scheduled_ground_time_minutes  \\\n",
      "51          UA           2177                              9   \n",
      "63          UA            767                             22   \n",
      "106         UA           2487                              3   \n",
      "126         UA           1304                             18   \n",
      "165         UA           1495                            102   \n",
      "168         UA           1776                             15   \n",
      "201         UA           1803                             23   \n",
      "209         UA            224                             23   \n",
      "213         UA           1564                            130   \n",
      "224         UA           2090                             61   \n",
      "\n",
      "     minimum_turn_minutes  \n",
      "51                     43  \n",
      "63                     62  \n",
      "106                    56  \n",
      "126                    56  \n",
      "165                   119  \n",
      "168                    51  \n",
      "201                    56  \n",
      "209                    51  \n",
      "213                   119  \n",
      "224                    57  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read relevant columns\n",
    "flights = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'scheduled_ground_time_minutes', 'minimum_turn_minutes']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines and valid positive values\n",
    "ua_flights = flights[\n",
    "    (flights['company_id'] == 'UA') &\n",
    "    (flights['scheduled_ground_time_minutes'] > 0) &\n",
    "    (flights['minimum_turn_minutes'] > 0)\n",
    "]\n",
    "\n",
    "# Define \"close to or below\" condition:\n",
    "# We'll consider flights where scheduled time is less than or equal to minimum turn + 10% buffer\n",
    "critical_flights = ua_flights[\n",
    "    ua_flights['scheduled_ground_time_minutes'] <= ua_flights['minimum_turn_minutes'] * 1.1\n",
    "]\n",
    "\n",
    "# Count how many flights meet this condition\n",
    "num_critical = critical_flights['flight_number'].nunique()\n",
    "\n",
    "print(f\"Number of UA flights with scheduled ground time close to or below minimum turn: {num_critical}\")\n",
    "print(critical_flights.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e4172ea-567c-451d-953b-ba8e939055fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\seema\\\\United-Airlines-CaseStudy\\\\Data\\\\raw\\\\Flight_Level_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# --- Step 1: Read your CSV file ---\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mseema\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUnited-Airlines-CaseStudy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFlight_Level_Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# --- Step 2: Make sure you have the correct columns ---\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Flight number column = 'Flight_ID' or 'flight_number'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Scheduled time column = 'scheduled_ground_time_minutes'\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# --- Step 3: Compute median of positive scheduled times per flight ---\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedian_Positive\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight_number\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduled_ground_time_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: x[x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\seema\\\\United-Airlines-CaseStudy\\\\Data\\\\raw\\\\Flight_Level_Data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Read your CSV file ---\n",
    "df = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight_Level_Data.csv')\n",
    "\n",
    "# --- Step 2: Make sure you have the correct columns ---\n",
    "# Flight number column = 'Flight_ID' or 'flight_number'\n",
    "# Scheduled time column = 'scheduled_ground_time_minutes'\n",
    "\n",
    "# --- Step 3: Compute median of positive scheduled times per flight ---\n",
    "df['Median_Positive'] = df.groupby('flight_number')['scheduled_ground_time_minutes'].transform(\n",
    "    lambda x: x[x > 0].median()\n",
    ")\n",
    "\n",
    "# --- Step 4: Replace negative scheduled times with the flight median ---\n",
    "df['Adjusted_Scheduled_Time'] = df['scheduled_ground_time_minutes'].where(\n",
    "    df['scheduled_ground_time_minutes'] > 0,\n",
    "    df['Median_Positive']\n",
    ")\n",
    "\n",
    "# --- Optional: Save the cleaned data ---\n",
    "df.to_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\Flight_Level_Data_Cleaned.csv', index=False)\n",
    "\n",
    "# --- Step 5: Inspect the result ---\n",
    "print(df[['flight_number', 'scheduled_ground_time_minutes', 'Median_Positive', 'Adjusted_Scheduled_Time']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "385c808f-aeb4-4719-b3fb-0d321ccc1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    flight_number  scheduled_ground_time_minutes  Median_Positive  \\\n",
      "0            4792                             42             58.0   \n",
      "1             920                            235            400.0   \n",
      "2            1776                             76             75.0   \n",
      "3            5790                            223             90.0   \n",
      "4            1398                             75             75.0   \n",
      "5            5470                             49             43.0   \n",
      "6             374                             54             75.0   \n",
      "7            1577                            123            101.5   \n",
      "8             881                            365            365.0   \n",
      "9            2006                             90             90.0   \n",
      "10            307                             94             94.0   \n",
      "11           1538                            100             95.5   \n",
      "12           1006                             63             64.0   \n",
      "13           4395                            132             72.0   \n",
      "14           1538                             95             95.5   \n",
      "15           2138                             62             62.5   \n",
      "16           4481                            644            742.5   \n",
      "17           5108                             85             77.5   \n",
      "18           3568                             75             68.0   \n",
      "19           4739                             69             62.5   \n",
      "\n",
      "    Adjusted_Scheduled_Time  \n",
      "0                      42.0  \n",
      "1                     235.0  \n",
      "2                      76.0  \n",
      "3                     223.0  \n",
      "4                      75.0  \n",
      "5                      49.0  \n",
      "6                      54.0  \n",
      "7                     123.0  \n",
      "8                     365.0  \n",
      "9                      90.0  \n",
      "10                     94.0  \n",
      "11                    100.0  \n",
      "12                     63.0  \n",
      "13                    132.0  \n",
      "14                     95.0  \n",
      "15                     62.0  \n",
      "16                    644.0  \n",
      "17                     85.0  \n",
      "18                     75.0  \n",
      "19                     69.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Read your CSV file ---\n",
    "df = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv')\n",
    "\n",
    "# --- Step 2: Make sure you have the correct columns ---\n",
    "# Flight number column = 'Flight_ID' or 'flight_number'\n",
    "# Scheduled time column = 'scheduled_ground_time_minutes'\n",
    "\n",
    "# --- Step 3: Compute median of positive scheduled times per flight ---\n",
    "df['Median_Positive'] = df.groupby('flight_number')['scheduled_ground_time_minutes'].transform(\n",
    "    lambda x: x[x > 0].median()\n",
    ")\n",
    "\n",
    "# --- Step 4: Replace negative scheduled times with the flight median ---\n",
    "df['Adjusted_Scheduled_Time'] = df['scheduled_ground_time_minutes'].where(\n",
    "    df['scheduled_ground_time_minutes'] > 0,\n",
    "    df['Median_Positive']\n",
    ")\n",
    "\n",
    "# --- Optional: Save the cleaned data ---\n",
    "df.to_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\Flight_Level_Data_Cleaned.csv', index=False)\n",
    "\n",
    "# --- Step 5: Inspect the result ---\n",
    "print(df[['flight_number', 'scheduled_ground_time_minutes', 'Median_Positive', 'Adjusted_Scheduled_Time']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7de9e3c5-1c68-4eb8-9d1d-37092f87eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      flight_number  scheduled_ground_time_minutes adjusted_scheduled_time  \\\n",
      "0              4792                             42                      42   \n",
      "1               920                            235                     235   \n",
      "2              1776                             76                      76   \n",
      "3              5790                            223                     223   \n",
      "4              1398                             75                      75   \n",
      "...             ...                            ...                     ...   \n",
      "8094           5027                             52                      52   \n",
      "8095           5037                             24                      24   \n",
      "8096           5135                            -16                    43.0   \n",
      "8097           5027                             52                      52   \n",
      "8098           5136                              8                       8   \n",
      "\n",
      "      was_negative  \n",
      "0            False  \n",
      "1            False  \n",
      "2            False  \n",
      "3            False  \n",
      "4            False  \n",
      "...            ...  \n",
      "8094         False  \n",
      "8095         False  \n",
      "8096          True  \n",
      "8097         False  \n",
      "8098         False  \n",
      "\n",
      "[8099 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your CSV\n",
    "df = pd.read_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv')\n",
    "\n",
    "# Ensure column names match your file\n",
    "# Flight ID = 'flight_number', Scheduled time = 'scheduled_ground_time_minutes'\n",
    "\n",
    "# Step 1: Compute median of positive scheduled times for each flight\n",
    "median_positive = df[df['scheduled_ground_time_minutes'] > 0].groupby('flight_number')['scheduled_ground_time_minutes'].median()\n",
    "\n",
    "# Step 2: Replace negative scheduled times with median of that flight\n",
    "def replace_negatives(row):\n",
    "    if row['scheduled_ground_time_minutes'] > 0:\n",
    "        return row['scheduled_ground_time_minutes']\n",
    "    else:\n",
    "        # If no positive values exist for that flight, return NaN or a placeholder\n",
    "        return median_positive.get(row['flight_number'], pd.NA)\n",
    "\n",
    "df['adjusted_scheduled_time'] = df.apply(replace_negatives, axis=1)\n",
    "\n",
    "# Optional: flag rows where replacement happened\n",
    "df['was_negative'] = df['scheduled_ground_time_minutes'] <= 0\n",
    "\n",
    "# Save the updated CSV\n",
    "df.to_csv(r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\Flight_Level_Adjusted.csv', index=False)\n",
    "\n",
    "print(df[['flight_number', 'scheduled_ground_time_minutes', 'adjusted_scheduled_time', 'was_negative']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdae9148-5fb4-425b-b964-57281437a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_type  flight_number  transfer_to_checked_ratio\n",
      "0                     3                       1.32\n",
      "1                    60                        NaN\n",
      "2                   118                       1.16\n",
      "3                   202                       0.47\n",
      "4                   205                        NaN\n",
      "..                  ...                        ...\n",
      "355                3018                       0.02\n",
      "356                3024                       0.47\n",
      "357                3025                       0.74\n",
      "358                3048                       0.24\n",
      "359                3748                       0.00\n",
      "\n",
      "[360 rows x 2 columns]\n",
      "\n",
      "Overall average ratio across all flights: 2.05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the Bag Level Information CSV\n",
    "bags = pd.read_csv(\n",
    "    r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Bag+Level+Data.csv',\n",
    "    usecols=['company_id', 'flight_number', 'bag_type']\n",
    ")\n",
    "\n",
    "# Filter for United Airlines only\n",
    "ua_bags = bags[bags['company_id'] == 'UA'].copy()\n",
    "\n",
    "# Clean and standardize bag_type\n",
    "ua_bags['bag_type'] = ua_bags['bag_type'].str.strip().str.lower()\n",
    "\n",
    "# Group by flight_number and count each bag_type\n",
    "bag_counts = ua_bags.groupby(['flight_number', 'bag_type']).size().unstack(fill_value=0)\n",
    "# Ensure all three columns exist\n",
    "for col in ['origin', 'transfer', 'hot transfer']:\n",
    "    if col not in bag_counts.columns:\n",
    "        bag_counts[col] = 0\n",
    "\n",
    "# Total transfer bags = transfer + hot transfer\n",
    "bag_counts['total_transfer'] = bag_counts['transfer'] + bag_counts['hot transfer']\n",
    "\n",
    "# Treat 'origin' as 'checked'\n",
    "bag_counts['checked'] = bag_counts['origin']\n",
    "\n",
    "# Calculate ratio safely\n",
    "bag_counts['transfer_to_checked_ratio'] = np.where(\n",
    "    bag_counts['checked'] == 0,\n",
    "    np.nan,\n",
    "    bag_counts['total_transfer'] / bag_counts['checked']\n",
    ")\n",
    "\n",
    "# Reset index\n",
    "bag_counts = bag_counts.reset_index()\n",
    "\n",
    "# Round ratios\n",
    "bag_counts['transfer_to_checked_ratio'] = bag_counts['transfer_to_checked_ratio'].round(2)\n",
    "# Print per-flight ratios\n",
    "print(bag_counts[['flight_number', 'transfer_to_checked_ratio']])\n",
    "\n",
    "# Overall average ratio\n",
    "overall_avg_ratio = bag_counts['transfer_to_checked_ratio'].mean()\n",
    "print(f\"\\nOverall average ratio across all flights: {overall_avg_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c907623f-4b34-4aee-aa7f-dc6312102f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   flight_number  total_seats  total_passengers  load_factor_percent\n",
      "0           4792           76              1132          1489.473684\n",
      "1            920          167              2642          1582.035928\n",
      "2           1776          166              2694          1622.891566\n",
      "3           5790           50               756          1512.000000\n",
      "4           1398          166              2264          1363.855422\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "flight_file = r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv'\n",
    "pnr_file = r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\PNR+Flight+Level+Data.csv'\n",
    "\n",
    "# Step 1: Read CSV files\n",
    "flights = pd.read_csv(flight_file)\n",
    "pnr = pd.read_csv(pnr_file)\n",
    "\n",
    "# Step 2: Aggregate total passengers per flight\n",
    "passenger_counts = pnr.groupby('flight_number')['total_pax'].sum().reset_index()\n",
    "passenger_counts.rename(columns={'total_pax': 'total_passengers'}, inplace=True)\n",
    "\n",
    "# Step 3: Merge Flight Level data with aggregated passenger counts\n",
    "flight_data = flights.merge(passenger_counts, on='flight_number', how='left')\n",
    "\n",
    "# Step 4: Calculate load factor (% of seats filled)\n",
    "flight_data['load_factor_percent'] = (flight_data['total_passengers'] / flight_data['total_seats']) * 100\n",
    "\n",
    "# Step 5: Optional – view result\n",
    "print(flight_data[['flight_number', 'total_seats', 'total_passengers', 'load_factor_percent']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "220d1c10-2794-42da-b116-c2fac922626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   flight_number scheduled_departure_date_local  total_seats  \\\n",
      "0           4792                     04-08-2025           76   \n",
      "1            920                     03-08-2025          167   \n",
      "2           1776                     10-08-2025          166   \n",
      "3           5790                     06-08-2025           50   \n",
      "4           1398                     05-08-2025          166   \n",
      "\n",
      "   total_passengers  load_factor_percent  \n",
      "0               NaN                  NaN  \n",
      "1               NaN                  NaN  \n",
      "2               NaN                  NaN  \n",
      "3               NaN                  NaN  \n",
      "4               NaN                  NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "flight_file = r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\Flight Level Data.csv'\n",
    "pnr_file = r'C:\\Users\\seema\\United-Airlines-CaseStudy\\Data\\raw\\PNR+Flight+Level+Data.csv'\n",
    "\n",
    "# Step 1: Read CSV files\n",
    "flights = pd.read_csv(flight_file)\n",
    "pnr = pd.read_csv(pnr_file)\n",
    "\n",
    "# Step 2: Aggregate total passengers per flight per date\n",
    "passenger_counts = (\n",
    "    pnr.groupby(['flight_number', 'scheduled_departure_date_local'])['total_pax']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "passenger_counts.rename(columns={'total_pax': 'total_passengers'}, inplace=True)\n",
    "\n",
    "# Step 3: Merge Flight Level data with aggregated passenger counts\n",
    "flight_data = flights.merge(\n",
    "    passenger_counts,\n",
    "    on=['flight_number', 'scheduled_departure_date_local'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 4: Calculate load factor (% of seats filled)\n",
    "flight_data['load_factor_percent'] = (flight_data['total_passengers'] / flight_data['total_seats']) * 100\n",
    "\n",
    "# Step 5: Optional – view result\n",
    "print(flight_data[['flight_number', 'scheduled_departure_date_local', 'total_seats', 'total_passengers', 'load_factor_percent']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bfa4ca-8a4e-4c10-b55f-0b6c2114bfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
